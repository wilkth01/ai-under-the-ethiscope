<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Misinformation, Deepfakes &amp; Epistemic Trust | AI Under the Ethiscope</title>
  <link rel="stylesheet" href="styles.css">
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
</head>
<body>

  <nav class="site-nav">
    <div class="nav-inner">
      <a href="index.html" class="nav-brand">
        <img src="images/ethiscope-logo.png" alt="AI Under the Ethiscope">
        <span>AI Under the Ethiscope</span>
      </a>
      <button class="nav-hamburger" onclick="document.querySelector('.nav-links').classList.toggle('open')" aria-label="Toggle menu">&#9776;</button>
      <ul class="nav-links">
        <li><a href="index.html">Home</a></li>
        <li><a href="index.html#framework">Framework</a></li>
        <li><a href="index.html#projects">Projects</a></li>
        <li><a href="index.html#pipeline">Ethics Pipeline</a></li>
      </ul>
    </div>
  </nav>

  <header class="project-hero">
    <div class="project-hero-content">
      <div class="breadcrumb"><a href="index.html">Home</a> &rsaquo; <a href="index.html#projects">Projects</a> &rsaquo; Misinformation &amp; Deepfakes</div>
      <div class="tag-line">Misinformation, Deepfakes &amp; Epistemic Trust</div>
      <h1>The Voice That Wasn't Real</h1>
      <p class="case-label">Case Study: Biden Deepfake Robocall &mdash; 2024 New Hampshire Primary</p>
    </div>
  </header>

  <section class="project-content">
    <div class="container">
      <div class="project-layout">
        <div class="project-main">

          <div class="source-docs">
            <h3>Source Documents</h3>
            <ul>
              <li><a href="documents/misinformation-deepfakes/Case-and-Mechanism-Explanation.docx"><span class="doc-icon">&#128196;</span> Case &amp; Mechanism Explanation</a></li>
              <li><a href="documents/misinformation-deepfakes/Field-Guide-Summary.docx"><span class="doc-icon">&#128196;</span> Field Guide Summary</a></li>
            </ul>
          </div>

          <h2>The Case</h2>
          <p>During the 2024 New Hampshire Democratic primary, citizens in Manchester received a robotic call that appeared to feature the voice of President Joe Biden. The AI-generated audio encouraged Democrats not to vote in the upcoming primary &mdash; a direct attempt at voter suppression through technological deception.</p>

          <img src="https://images.unsplash.com/photo-1586920740099-f3ceb65bc51e?w=900&h=450&fit=crop" alt="News media and misinformation" class="feature-image">

          <p>The deepfake audio exploited AI voice-cloning technology to create a convincing imitation of a trusted political figure, weaponizing the relationship of trust between voters and their elected officials.</p>

          <h2>The Mechanism of Harm</h2>
          <p>The core mechanism is deception through deepfake audio technology. By generating a realistic imitation of a prominent political figure's voice, the perpetrators exploited pre-existing epistemic trust &mdash; the reasonable assumption that authority figures like the President provide truthful and accurate information.</p>

          <div class="callout">
            <h4>How Epistemic Trust Is Weaponized</h4>
            <p>Voters reasonably assume that communications from political leaders are authentic. Deepfake technology exploits this trust, turning it into a vulnerability. When the voice sounds real, the brain processes it as real &mdash; even a brief moment of doubt can achieve the goal of voter suppression.</p>
          </div>

          <h2>Who Is Affected?</h2>
          <ul>
            <li><strong>Citizens and voters:</strong> Their ability to make informed political decisions was directly undermined by the fake call</li>
            <li><strong>President Biden:</strong> His identity and credibility were impersonated, causing reputation harm and public confusion</li>
            <li><strong>Political parties:</strong> Democratic systems rely on public trust and accurate information flow</li>
            <li><strong>The broader democratic system:</strong> Built on epistemic trust and the assumption that citizens can access reliable information</li>
          </ul>

          <h2>The Ethical Stakes</h2>
          <p>The case illuminates several critical ethical dimensions:</p>
          <ul>
            <li><strong>Autonomy:</strong> When provided with misinformation, voters cannot make truly informed choices &mdash; their decisions are no longer fully autonomous</li>
            <li><strong>Harm:</strong> Biden's identity was weaponized, and citizens were targeted for manipulation of their most fundamental democratic right</li>
            <li><strong>Deception:</strong> The technology's entire purpose was to deceive, making the ethical violation intentional rather than incidental</li>
            <li><strong>Epistemic trust:</strong> Incidents like this erode public confidence in all media, technology, and political communication</li>
          </ul>

          <div class="callout callout-gold">
            <h4>The Broader Threat</h4>
            <p>Deepfakes are not just individual incidents of deception. They systematically undermine the shared epistemic foundations that democratic participation requires. When voters can no longer trust what they hear, the very possibility of informed consent in a democracy is threatened.</p>
          </div>

        </div>

        <aside class="project-sidebar">
          <div class="sidebar-card">
            <h4>Quick Facts</h4>
            <ul>
              <li><strong>Event:</strong> 2024 NH Primary</li>
              <li><strong>Technology:</strong> AI voice cloning</li>
              <li><strong>Target:</strong> Democratic voters</li>
              <li><strong>Goal:</strong> Voter suppression</li>
              <li><strong>Impersonated:</strong> President Biden</li>
            </ul>
          </div>
          <div class="sidebar-card">
            <h4>Pipeline Stages</h4>
            <ul>
              <li><strong>Primary:</strong> Model / System</li>
              <li><strong>Secondary:</strong> Outcomes</li>
              <li><strong>Missing:</strong> Oversight &amp; Governance</li>
            </ul>
          </div>
          <div class="sidebar-card">
            <h4>Ethical Dimensions</h4>
            <ul>
              <li>Autonomy &mdash; informed choice denied</li>
              <li>Harm &mdash; identity weaponization</li>
              <li>Rights &mdash; democratic participation</li>
              <li>Accountability &mdash; attribution difficulty</li>
            </ul>
          </div>
          <div class="sidebar-card">
            <h4>All Projects</h4>
            <div class="sidebar-nav">
              <a href="bias-discrimination.html">Bias &amp; Discrimination</a>
              <a href="labor-automation.html">Labor &amp; Automation</a>
              <a href="intellectual-property.html">Intellectual Property</a>
              <a href="human-agency.html">Human Agency</a>
              <a href="ethical-obligations-ai.html">Moral Status of AI</a>
              <a href="power-monopoly.html">Power &amp; Monopoly</a>
              <a href="safety-security.html">Safety &amp; Security</a>
              <a href="environmental-impact.html">Environmental Impact</a>
              <a href="privacy-surveillance.html">Privacy &amp; Consent</a>
            </div>
          </div>
        </aside>
      </div>
    </div>
  </section>

  <footer class="site-footer">
    <div class="footer-inner">
      <div class="footer-col">
        <div class="footer-logos">
          <img src="images/ethiscope-logo.png" alt="Ethiscope Logo">
          <img src="images/ai-week-logo.png" alt="AI Week 2026">
        </div>
        <p>A PHIL 388 project exploring the ethical dimensions of artificial intelligence.</p>
      </div>
      <div class="footer-col">
        <h4>Projects</h4>
        <ul>
          <li><a href="bias-discrimination.html">Bias &amp; Discrimination</a></li>
          <li><a href="labor-automation.html">Labor &amp; Automation</a></li>
          <li><a href="intellectual-property.html">Intellectual Property</a></li>
          <li><a href="human-agency.html">Human Agency</a></li>
          <li><a href="misinformation-deepfakes.html">Misinformation &amp; Deepfakes</a></li>
        </ul>
      </div>
      <div class="footer-col">
        <h4>More Projects</h4>
        <ul>
          <li><a href="ethical-obligations-ai.html">Moral Status of AI</a></li>
          <li><a href="power-monopoly.html">Power &amp; Monopoly</a></li>
          <li><a href="safety-security.html">Safety &amp; Security</a></li>
          <li><a href="environmental-impact.html">Environmental Impact</a></li>
          <li><a href="privacy-surveillance.html">Privacy &amp; Consent</a></li>
        </ul>
      </div>
    </div>
    <div class="footer-bottom">
      <p>Widener University &middot; PHIL 388: Ethics of Artificial Intelligence &middot; Dr. Tom Wilk &middot; Spring 2026</p>
    </div>
  </footer>

  <script src="easter-egg.js"></script>
</body>
</html>
