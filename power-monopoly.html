<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Power, Monopoly &amp; Political Economy | AI Under the Ethiscope</title>
  <link rel="stylesheet" href="styles.css">
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
</head>
<body>

  <nav class="site-nav">
    <div class="nav-inner">
      <a href="index.html" class="nav-brand">
        <img src="images/ethiscope-logo.png" alt="AI Under the Ethiscope">
        <span>AI Under the Ethiscope</span>
      </a>
      <button class="nav-hamburger" onclick="document.querySelector('.nav-links').classList.toggle('open')" aria-label="Toggle menu">&#9776;</button>
      <ul class="nav-links">
        <li><a href="index.html">Home</a></li>
        <li><a href="index.html#framework">Framework</a></li>
        <li><a href="index.html#projects">Projects</a></li>
        <li><a href="index.html#pipeline">Ethics Pipeline</a></li>
      </ul>
    </div>
  </nav>

  <header class="project-hero">
    <div class="project-hero-content">
      <div class="breadcrumb"><a href="index.html">Home</a> &rsaquo; <a href="index.html#projects">Projects</a> &rsaquo; Power &amp; Monopoly</div>
      <div class="tag-line">Power, Monopoly &amp; Political Economy</div>
      <h1>Who Controls the AI?</h1>
      <p class="case-label">Case Study: Microsoft-OpenAI Partnership &amp; the FTC Inquiry (2024)</p>
    </div>
  </header>

  <section class="project-content">
    <div class="container">
      <div class="project-layout">
        <div class="project-main">

          <div class="source-docs">
            <h3>Source Documents</h3>
            <ul>
              <li><a href="documents/power-monopoly/Case-and-Mechanism-Explanation.docx"><span class="doc-icon">&#128196;</span> Case &amp; Mechanism Explanation</a></li>
              <li><a href="documents/power-monopoly/Field-Guide-Summary.docx"><span class="doc-icon">&#128196;</span> Field Guide Summary</a></li>
            </ul>
          </div>

          <div class="student-byline">
            <span class="byline-label">Researchers:</span>
            <span class="student-chip">Trevor Fursman <span class="student-school">&middot; Dwyer School of Nursing</span></span>
            <span class="student-chip">Salient Nkongho Enoh</span>
            <span class="student-chip">Lamiracle Summers</span>
          </div>

          <h2>The Case</h2>
          <p>Microsoft has become one of the primary financial and infrastructure partners behind OpenAI, investing billions of dollars and integrating OpenAI's models into products like Azure and Microsoft 365. As OpenAI shifted from a nonprofit research lab toward a more for-profit structure, critics and regulators questioned how these large investments might shape AI development, deployment, and governance.</p>

          <img src="https://images.unsplash.com/photo-1553877522-43269d4ea984?w=900&h=450&fit=crop" alt="Corporate headquarters and power" class="feature-image">

          <p>In 2024, the U.S. Federal Trade Commission opened an inquiry into major AI partnerships, including Microsoft's connection with OpenAI, to examine possible risks to competition and innovation in the AI industry.</p>

          <h2>The Ethical Pipeline</h2>
          <p>The concentration of AI power follows a chain of connected steps:</p>
          <ol>
            <li><strong>Data control:</strong> Large technology companies collect and control massive proprietary datasets that influence how AI systems are trained, potentially reinforcing biases or corporate priorities</li>
            <li><strong>Development priorities:</strong> Companies focus on efficiency, scalability, and market success, which may conflict with values like justice, transparency, or democratic oversight</li>
            <li><strong>Deployment opacity:</strong> Once deployed, AI systems are protected as intellectual property, making independent auditing difficult</li>
            <li><strong>Institutional adoption:</strong> Public institutions adopt proprietary tools for productivity, shifting decision-making power from public organizations to private providers</li>
            <li><strong>Individual impact:</strong> People affected by AI-driven decisions struggle to question or appeal outcomes because the systems are complex and opaque</li>
          </ol>

          <div class="callout">
            <h4>Differential Power</h4>
            <p>Large technology companies and investors gain economic and strategic advantages. Public institutions gain efficiency but may lose autonomy. Individuals &mdash; especially marginalized communities &mdash; face the most uncertainty, as their data may be used without meaningful consent and they may experience disproportionate harm.</p>
          </div>

          <h2>Who Is Affected?</h2>
          <ul>
            <li><strong>Large tech companies and investors:</strong> Gain economic and strategic advantages through market concentration</li>
            <li><strong>Public institutions:</strong> Gain efficiency but may surrender autonomy to private technology providers</li>
            <li><strong>Smaller startups and nonprofits:</strong> Pushed aside by resource disparities and concentrated market power</li>
            <li><strong>Everyday users:</strong> Have far less control over how AI shapes their lives</li>
            <li><strong>Marginalized communities:</strong> Face disproportionate risks from systems they had no role in designing</li>
          </ul>

          <h2>The Ethical Stakes</h2>
          <p>AI is now embedded in everyday systems like education, healthcare, and hiring, yet the power to build and control these tools is concentrated in a small number of corporations. While collaborations like Microsoft-OpenAI accelerate innovation, they shift decision-making influence away from democratic institutions toward private actors whose accountability to the public is limited.</p>

          <div class="callout callout-gold">
            <h4>Key Ethical Questions</h4>
            <p>How should public institutions balance efficiency and accountability when adopting AI tools from private corporations? How much transparency should private AI companies owe to the public institutions that rely on their systems? When does efficiency gained through AI become ethically unacceptable if it reduces accountability or public participation?</p>
          </div>

        </div>

        <aside class="project-sidebar">
          <div class="sidebar-card">
            <h4>Quick Facts</h4>
            <ul>
              <li><strong>Partnership:</strong> Microsoft-OpenAI</li>
              <li><strong>Regulator:</strong> FTC (2024)</li>
              <li><strong>Products:</strong> Azure, Microsoft 365</li>
              <li><strong>Shift:</strong> Nonprofit to for-profit</li>
              <li><strong>Concern:</strong> Market concentration</li>
            </ul>
          </div>
          <div class="sidebar-card">
            <h4>Pipeline Stages</h4>
            <ul>
              <li><strong>Primary:</strong> Procurement</li>
              <li><strong>Secondary:</strong> Policy Goals</li>
              <li><strong>Tertiary:</strong> Oversight &amp; Governance</li>
              <li><strong>Impact:</strong> Outcomes</li>
            </ul>
          </div>
          <div class="sidebar-card">
            <h4>Ethical Dimensions</h4>
            <ul>
              <li>Justice &mdash; power concentration</li>
              <li>Accountability &mdash; democratic oversight</li>
              <li>Autonomy &mdash; institutional independence</li>
              <li>Rights &mdash; consent and transparency</li>
            </ul>
          </div>
          <div class="sidebar-card">
            <h4>Key References</h4>
            <ul>
              <li>FTC AI Partnership Inquiry (2024)</li>
              <li>Crawford, <em>Atlas of AI</em> (2021)</li>
              <li>EU Ethics Guidelines for AI (2019)</li>
            </ul>
          </div>
          <div class="sidebar-card">
            <h4>All Projects</h4>
            <div class="sidebar-nav">
              <a href="bias-discrimination.html">Bias &amp; Discrimination</a>
              <a href="labor-automation.html">Labor &amp; Automation</a>
              <a href="intellectual-property.html">Intellectual Property</a>
              <a href="human-agency.html">Human Agency</a>
              <a href="misinformation-deepfakes.html">Misinformation &amp; Deepfakes</a>
              <a href="ethical-obligations-ai.html">Moral Status of AI</a>
              <a href="safety-security.html">Safety &amp; Security</a>
              <a href="environmental-impact.html">Environmental Impact</a>
              <a href="privacy-surveillance.html">Privacy &amp; Consent</a>
            </div>
          </div>
        </aside>
      </div>
    </div>
  </section>

  <footer class="site-footer">
    <div class="footer-inner">
      <div class="footer-col">
        <div class="footer-logos">
          <img src="images/ethiscope-logo.png" alt="Ethiscope Logo">
          <img src="images/ai-week-logo.png" alt="AI Week 2026">
        </div>
        <p>A PHIL 388 project exploring the ethical dimensions of artificial intelligence.</p>
      </div>
      <div class="footer-col">
        <h4>Projects</h4>
        <ul>
          <li><a href="bias-discrimination.html">Bias &amp; Discrimination</a></li>
          <li><a href="labor-automation.html">Labor &amp; Automation</a></li>
          <li><a href="intellectual-property.html">Intellectual Property</a></li>
          <li><a href="human-agency.html">Human Agency</a></li>
          <li><a href="misinformation-deepfakes.html">Misinformation &amp; Deepfakes</a></li>
        </ul>
      </div>
      <div class="footer-col">
        <h4>More Projects</h4>
        <ul>
          <li><a href="ethical-obligations-ai.html">Moral Status of AI</a></li>
          <li><a href="power-monopoly.html">Power &amp; Monopoly</a></li>
          <li><a href="safety-security.html">Safety &amp; Security</a></li>
          <li><a href="environmental-impact.html">Environmental Impact</a></li>
          <li><a href="privacy-surveillance.html">Privacy &amp; Consent</a></li>
        </ul>
      </div>
    </div>
    <div class="footer-bottom">
      <p>Widener University &middot; PHIL 388: Ethics of Artificial Intelligence &middot; Dr. Tom Wilk &middot; Spring 2026</p>
    </div>
  </footer>

  <script src="easter-egg.js"></script>
</body>
</html>
